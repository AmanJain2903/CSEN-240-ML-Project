# -*- coding: utf-8 -*-
"""VotingEnsemble.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TowmYuo8v8R_fEX1HragtncHeaBDZ2wD

# IMPORTS
"""

import tensorflow as tf
from sklearn.metrics import precision_recall_curve
import numpy as np
import os
from tensorflow.keras.metrics import Precision, Recall, AUC
from sklearn.metrics import f1_score, classification_report
import json
import gc

"""# DATA PREPARATION"""

dataPath = 'Dataset/'
categories = ["Normal","Osteopenia", "Osteoporosis"]

img_size = (224, 224)
channels = 3
img_shape = (img_size[0], img_size[1], channels)
batch_size = 16

trainDirectory = dataPath + "train"
testDirectory = dataPath + "test"
valDirectory = dataPath + "val"

trainDataset = tf.keras.utils.image_dataset_from_directory(
    trainDirectory,
    labels='inferred',
    label_mode='categorical',
    class_names=categories,
    color_mode='rgb',
    image_size=img_size,
    shuffle=True,
    seed=99,
    validation_split=None,
    batch_size=None,
    subset=None,
)

validDataset = tf.keras.utils.image_dataset_from_directory(
    valDirectory,
    labels='inferred',
    label_mode='categorical',
    class_names=categories,
    color_mode='rgb',
    image_size=img_size,
    shuffle=True,
    seed=99,
    validation_split=None,
    batch_size=None,
    subset=None,
)

testDataset = tf.keras.utils.image_dataset_from_directory(
    testDirectory,
    labels='inferred',
    label_mode='categorical',
    class_names=categories,
    color_mode='rgb',
    image_size=img_size,
    shuffle=True,
    seed=99,
    validation_split=None,
    batch_size=None,
    subset=None,
)

def normalize(image, label):
    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0
    return image, label

trainDataset = trainDataset.map(normalize)
validDataset = validDataset.map(normalize)
testDataset = testDataset.map(normalize)

trainDataset = trainDataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
validDataset = validDataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
testDataset = testDataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)

"""# MODELS"""

thresholdsPath = 'Thresholds/'
kerasModelsPath = 'KerasModels/'

modelNames = os.listdir(kerasModelsPath)

models = []
for modelName in modelNames:
    modelPath = kerasModelsPath + modelName
    model = tf.keras.models.load_model(modelPath)
    results = model.evaluate(validDataset, return_dict=True)
    models.append([modelName, results['auc']])

models.sort(key=lambda x: x[1], reverse=True)
modelNames = [model[0] for model in models]
modelNames

"""# ENSEMBLING FUNCTION"""

def ensembleModels(predictedClasses):
    votedPredictions = []
    numModels = len(predictedClasses)
    samples = len(predictedClasses[0])
    for i in range(samples):
        count0, count1, count2 = 0, 0, 0
        for j in range(numModels):
            if predictedClasses[j][i] == 0:
                count0 += 1
            elif predictedClasses[j][i] == 1:
                count1 += 1
            else:
                count2 += 1
        if count0 > count1 and count0 > count2:
            votedPredictions.append(0)
        elif count1 > count0 and count1 > count2:
            votedPredictions.append(1)
        else:
            votedPredictions.append(2)
    return votedPredictions

def customPredict(yPred, thresholds):
    predictions = np.zeros_like(yPred)
    for i in thresholds.keys():
        threshold = thresholds[i]
        predictions[:, i] = (yPred[:, i] >= threshold).astype(int)
    predictions = np.argmax(predictions * yPred, axis=1)
    return predictions

def predict(modelNames, testDataset):
    predictedClasses = []
    for modelName in modelNames:
        name = modelName.split('.')[0]
        modelPath = kerasModelsPath + modelName
        model = tf.keras.models.load_model(modelPath)
        predictions = model.predict(testDataset)
        thresholdPath = thresholdsPath + name + '.json'
        with open(thresholdPath, 'r') as f:
            threshold = json.load(f)
            threshold = {int(k): v for k, v in threshold.items()}
        predicted = customPredict(predictions, threshold)
        predictedClasses.append(predicted)
        tf.keras.backend.clear_session()
        del model
        gc.collect()
    return ensembleModels(predictedClasses)

bestAverageF1 = -1
topK = -1
bestModels = None

yTrue = []
for xBatch, yBatch in testDataset:
    yTrue.extend(np.argmax(yBatch.numpy(), axis=1))

for k in range(2, len(modelNames)+1):
    print(f"Top {k} : {modelNames[:k]}")
    yPred = predict(modelNames[:k], testDataset)
    f1 = f1_score(yTrue, yPred, average='weighted')
    if f1 > bestAverageF1:
        bestAverageF1 = f1
        topK = k
        bestModels = modelNames[:k]
    report = classification_report(yTrue, yPred, target_names=categories)
    print("F1 Score: ", f1)
    print(report)

"""# EVALUATION"""

yTrue = []
for xBatch, yBatch in testDataset:
    yTrue.extend(np.argmax(yBatch.numpy(), axis=1))

yPred = predict(bestModels, testDataset)

report = classification_report(yTrue, yPred, target_names=categories)
print(report)